from .config import Config
from .parser import TweetParser
from .translator import Translator
from .archiver import Archiver
from push_queue import PushQueue
import time
import logging
import requests
import random
from typing import List, Dict
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from datetime import datetime, timedelta
import os
import json
from .instance_manager import InstanceManager
import asyncio
from .chrome_fetcher import ChromeFetcher
import signal
from .image_server import ImageServer

class TwitterMonitor:
    def __init__(self):
        self.config = Config()
        self.parser = TweetParser(self.config)
        self.translator = Translator(self.config)
        self.archiver = Archiver(self.config)
        self.push_queue = PushQueue()
        
        # æ·»åŠ æ—¶åŒºé…ç½®
        self.timezone = self.config.timezone
        
        # å®ä¾‹ç®¡ç†å™¨
        self.instance_manager = InstanceManager(self.config.archive_dir, self.config.proxies)
        
        # åˆå§‹åŒ–ä¼šè¯
        self.session = requests.Session()
        retry = Retry(total=3, backoff_factor=0.5)
        self.session.mount('http://', HTTPAdapter(max_retries=retry))
        self.session.mount('https://', HTTPAdapter(max_retries=retry))
        
        # æ¯å¤©æ¸…ç†ä¸€æ¬¡å®ä¾‹çŠ¶æ€
        self.last_cleanup = time.time()  # åˆå§‹åŒ–ä¸ºå½“å‰æ—¶é—´
        self.cleanup_interval = 24 * 3600  # 24å°æ—¶
        
        # æ·»åŠ ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self._handle_shutdown)
        signal.signal(signal.SIGTERM, self._handle_shutdown)
        
        self._shutdown = False
        self._loop = None  # ä¿å­˜äº‹ä»¶å¾ªç¯çš„å¼•ç”¨
        
        # åˆ›å»ºå¹¶å¯åŠ¨å›¾ç‰‡æœåŠ¡å™¨
        self.image_server = ImageServer(
            screenshots_dir=self.config.screenshots_dir,
            port=self.config.image_port,
            host=self.config.host
        )
        self.image_server.start()  # éé˜»å¡å¯åŠ¨
        
        self._chrome_fetcher = None  # åªä¿æŒä¸€ä¸ª Chrome å®ä¾‹
        
    def _handle_shutdown(self, signum, frame):
        """å¤„ç†å…³é—­ä¿¡å·"""
        if self._shutdown:  # å¦‚æœå·²ç»åœ¨å…³é—­ä¸­ï¼Œç›´æ¥è¿”å›
            return
            
        logging.info("æ¥æ”¶åˆ°å…³é—­ä¿¡å·,å¼€å§‹æ¸…ç†...")
        self._shutdown = True
        
        try:
            # å…ˆå…³é—­æ‰€æœ‰ Chrome è¿æ¥
            if hasattr(self, '_active_chrome_fetchers'):
                for fetcher in list(self._active_chrome_fetchers):
                    try:
                        # å¼ºåˆ¶åŒæ­¥å…³é—­
                        if self._loop and self._loop.is_running():
                            self._loop.run_until_complete(fetcher.close())
                    except:
                        pass
            
            # è¿è¡Œæ¸…ç†è„šæœ¬
            try:
                from scripts.cleanup_chrome import cleanup
                cleanup()
            except:
                pass
            
            # å¼ºåˆ¶é€€å‡ºè¿›ç¨‹
            logging.info("Chrome å®ä¾‹å·²æ¸…ç†ï¼Œæ­£åœ¨é€€å‡º...")
            os._exit(0)
            
        except Exception as e:
            logging.error(f"å…³é—­æ—¶å‡ºé”™: {str(e)}")
            os._exit(1)

    async def _get_chrome_fetcher(self):
        """è·å–æˆ–åˆ›å»º Chrome è¿æ¥"""
        try:
            if not self._chrome_fetcher:
                self._chrome_fetcher = ChromeFetcher(self.config)
                await self._chrome_fetcher.connect()
                logging.info("åˆ›å»ºæ–°çš„ Chrome è¿æ¥")
            elif not await self._chrome_fetcher.check_connection():
                # å¦‚æœè¿æ¥æ£€æŸ¥å¤±è´¥ï¼Œåˆ›å»ºæ–°è¿æ¥
                logging.warning("Chrome è¿æ¥å·²æ–­å¼€ï¼Œåˆ›å»ºæ–°è¿æ¥")
                self._chrome_fetcher = ChromeFetcher(self.config)
                await self._chrome_fetcher.connect()
            return self._chrome_fetcher
        except Exception as e:
            logging.error(f"è·å– Chrome è¿æ¥å¤±è´¥: {str(e)}")
            raise

    async def _fetch_tweets_async(self, instance: str, username: str):
        """å¼‚æ­¥è·å–æ¨æ–‡"""
        fetcher = await self._get_chrome_fetcher()
        return await fetcher.fetch_tweets(instance, username)

    def get_tweets_with_retry(self, username: str, max_retries: int = 5) -> List[Dict]:
        """å¸¦é‡è¯•æœºåˆ¶çš„æ¨æ–‡è·å–"""
        retries = 0
        while retries < max_retries:
            instance = self.instance_manager.select_instance()
            if not instance:
                logging.error("æ— å¯ç”¨å®ä¾‹")
                time.sleep(5)
                retries += 1
                continue
            
            try:
                # ä½¿ç”¨å¼‚æ­¥æ–¹å¼è·å–æ¨æ–‡
                loop = asyncio.get_event_loop()
                html_content = loop.run_until_complete(
                    self._fetch_tweets_async(instance, username)
                )
                
                # è§£ææ¨æ–‡
                tweets = self.parser.parse_tweets(html_content)
                if tweets:
                    # æ·»åŠ æˆªå›¾è·¯å¾„ï¼ˆæ¨æ–‡ID.pngï¼‰
                    for tweet in tweets:
                        tweet['screenshot'] = os.path.join(
                            self.config.screenshots_dir,
                            f"{tweet['id']}.png"
                        )
                    
                    self.instance_manager.update_health(instance, True)
                    logging.info(f"ä» {instance} æˆåŠŸè·å–åˆ° {len(tweets)} æ¡æ¨æ–‡")
                    return tweets
                else:
                    logging.warning(f"ä» {instance} è·å–åˆ°ç©ºçš„æ¨æ–‡åˆ—è¡¨")
                    self.instance_manager.update_health(instance, False)
                    
            except Exception as e:
                logging.error(f"è·å–æ¨æ–‡å¤±è´¥ ({instance}): {str(e)}")
                self.instance_manager.update_health(instance, False)
            
            retries += 1
            if retries < max_retries:
                time.sleep(2 * (retries + 1))
        
        logging.error(f"åœ¨å°è¯• {max_retries} æ¬¡åä»æœªèƒ½è·å–æ¨æ–‡")
        return []

    def check_updates(self):
        """æ£€æŸ¥æ‰€æœ‰ç”¨æˆ·çš„æ›´æ–°"""
        try:
            # æ·»åŠ æ›´è¯¦ç»†çš„æ—¥å¿—
            logging.info("=" * 50)
            logging.info("å¼€å§‹æ£€æŸ¥ä»¥ä¸‹ç”¨æˆ·çš„æ›´æ–°:")
            for name, username in self.config.users.items():
                logging.info(f"- {name}: @{username}")
            logging.info("=" * 50)
            
            for name, username in self.config.users.items():
                self._process_user_updates(name, username)
                
        except Exception as e:
            logging.error(f"æ£€æŸ¥æ›´æ–°è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {str(e)}", exc_info=True)
            self.push_queue.push(
                "ğŸš¨ Twitterç›‘æ§å‘ç”Ÿé”™è¯¯",
                f"### âš ï¸ é”™è¯¯ä¿¡æ¯\n\n{str(e)}\n\nè¯·æ£€æŸ¥æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯ã€‚"
            )

    def run(self):
        """è¿è¡Œç›‘æ§ç¨‹åº"""
        logging.info("Starting Twitter monitor...")
        self._loop = asyncio.new_event_loop()
        asyncio.set_event_loop(self._loop)
        
        try:
            # ç›´æ¥å¯åŠ¨å›¾ç‰‡æœåŠ¡å™¨ï¼ˆéé˜»å¡ï¼‰
            self.image_server.start()
            
            while not self._shutdown:
                try:
                    # å®šæœŸæ£€æŸ¥ Chrome è¿æ¥çŠ¶æ€
                    if self._chrome_fetcher:
                        # ä½¿ç”¨ run_until_complete è€Œä¸æ˜¯ create_task
                        self._loop.run_until_complete(self._chrome_fetcher.check_connection())
                    
                    now = time.time()
                    if now - self.last_cleanup >= self.cleanup_interval:
                        self.instance_manager.cleanup_expired()
                        self.last_cleanup = now
                    
                    # æ‰§è¡Œä¸»è¦çš„æ£€æŸ¥æ›´æ–°ä»»åŠ¡
                    self.check_updates()
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦å…³é—­
                    if self._shutdown:
                        break
                    
                    logging.info(f"ç­‰å¾… {self.config.check_interval} ç§’")
            
                   
                    
                    # ä½¿ç”¨äº‹ä»¶å¾ªç¯ç­‰å¾…
                    self._loop.run_until_complete(asyncio.sleep(self.config.check_interval))
                    
                except asyncio.CancelledError:
                    logging.info("ä»»åŠ¡è¢«å–æ¶ˆ")
                    break
                except Exception as e:
                    logging.error(f"Unexpected error: {str(e)}", exc_info=True)
                    if not self._shutdown:
                        # å‡ºé”™åç­‰å¾…ä¸€åˆ†é’Ÿå†é‡è¯•
                        self._loop.run_until_complete(asyncio.sleep(60))
                    
        finally:
            # æ¸…ç†èµ„æº
            try:
                self._cleanup()
            finally:
                # ç¡®ä¿äº‹ä»¶å¾ªç¯è¢«å…³é—­
                try:
                    if not self._loop.is_closed():
                        self._loop.run_until_complete(self._loop.shutdown_asyncgens())
                        self._loop.close()
                except Exception as e:
                    logging.error(f"å…³é—­äº‹ä»¶å¾ªç¯æ—¶å‡ºé”™: {str(e)}")
                logging.info("Twitter monitor stopped.")

    async def _cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            # å…³é—­ Chrome è¿æ¥
            if self._chrome_fetcher:
                await self._chrome_fetcher.close()
                self._chrome_fetcher = None
            
            # åœæ­¢å›¾ç‰‡æœåŠ¡å™¨
            if hasattr(self, 'image_server'):
                self.image_server.stop()
            
        except Exception as e:
            logging.error(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {str(e)}")

    def push_tweet(self, tweet: Dict, analysis: str) -> bool:
        """æ¨é€æ¨æ–‡"""
        try:
            logging.debug(f"å¼€å§‹å¤„ç†æ¨æ–‡: {tweet.get('id')}")
            logging.debug(f"analysis ç±»å‹: {type(analysis)}")
            logging.debug(f"analysis å†…å®¹: {analysis}")
            
            # æ„å»ºæ ‡é¢˜éƒ¨åˆ†
            title_parts = []
            
            # 1. ä» hints ä¸­æå–ç‰¹æ®Šæ ‡è®°
            hints = self.translator.extract_section(analysis, "é‡ç‚¹æç¤º")
            if hints:
                logging.debug(f"å¤„ç† hints ä¸­çš„ emoji: {hints}")  # è°ƒè¯•æ—¥å¿—
                # æŒ‰ä¼˜å…ˆçº§é¡ºåºæ£€æŸ¥è¡¨æƒ…ç¬¦å·
                for emoji in ['ğŸ’°', 'ğŸš€', 'ğŸ¤–', 'ğŸ’Š', 'ğŸ€„']:
                    if emoji in hints:
                        title_parts.append(emoji)
                        logging.debug(f"æ‰¾åˆ°å¹¶æ·»åŠ  emoji: {emoji}")  # è°ƒè¯•æ—¥å¿—
                        break
            
            # 2. æ·»åŠ è½¬å‘/å¼•ç”¨æ ‡è®°
            if tweet.get('is_retweet'):
                title_parts.append("ğŸ”„ [è½¬å‘]")
            elif tweet.get('is_quote'):
                title_parts.append("ğŸ’¬ [å¼•ç”¨]")
            
            # 3. æ·»åŠ ä½œè€…æ ‡è®°
            title_parts.append(f"ã€{tweet['name']}ã€‘")
            
            # 4. æ·»åŠ å†…å®¹æ¦‚è¦
            summary = self.translator.extract_section(analysis, "å†…å®¹æ¦‚è¦")
            if summary:
                title_parts.append(summary)
            
            # ç»„åˆæ ‡é¢˜
            title = " ".join(title_parts)
            
            # æ ‡é¢˜å¢åŠ é¢œè‰²
            
            # æ·»åŠ åª’ä½“ä¿¡æ¯
            media_section = ""
            if tweet.get('media'):
                media_section = "\n### ğŸ“· åª’ä½“\n\n"
                for media in tweet['media']:
                    media_type = media.get('type', 'unknown')
                    if media_type == 'image':
                        media_section += f"![å›¾ç‰‡]({media.get('url')})\n"
                    elif media_type == 'video':
                        media_section += f"ğŸ¬ [è§†é¢‘é“¾æ¥]({media.get('url')})\n"
                    elif media_type == 'gif':
                        media_section += f"ğŸï¸ [GIF]({media.get('url')})\n"

           

            # æ·»åŠ è½¬å‘/å¼•ç”¨ä¿¡æ¯
            reference_section = ""
            if tweet.get('is_retweet') and tweet.get('retweet_author'):
                reference_section = (
                    f"\n### ğŸ”„ è½¬å‘è‡ª\n\n"
                    f"**@{tweet['retweet_author']}**\n\n"
                )
            elif tweet.get('is_quote') and tweet.get('quote_text'):
                reference_section = (
                    f"\n### ğŸ’¬ å¼•ç”¨æ¨æ–‡\n\n"
                    f"**@{tweet.get('quote_author', 'æœªçŸ¥ç”¨æˆ·')}**ï¼š\n"
                    f"{tweet['quote_text']}\n\n"
                )

            # ç¡®ä¿ tweet_id æ˜¯æ¸…ç†è¿‡çš„
            tweet_id = tweet['id'].split('#')[0].split('?')[0]
            image_url = f"{self.config.image_base_url}/images/{tweet_id}.png"
            screenshot_section = (
                f"\n### ğŸ“¸ æˆªå›¾\n\n"
                f"![æ¨æ–‡æˆªå›¾]({image_url})\n"
            )

            # ç»„åˆå®Œæ•´å†…å®¹
            content = (
                f"### ğŸ“Š AIåˆ†æ\n\n"
                f"{analysis}\n\n"
                f"### â„¹ï¸ è¯¦ç»†ä¿¡æ¯\n\n"
                f"- **ğŸ“… å‘å¸ƒæ—¶é—´**: {tweet.get('time','æœªçŸ¥')}\n"
                f"- **ğŸ“… å‘å¸ƒæ—¥æœŸ**: {tweet.get('formatted_time','-')}\n"
                f"- **ğŸ”— åŸæ–‡é“¾æ¥**: [ç‚¹å‡»æŸ¥çœ‹]({tweet.get('url', '#')})\n"
                f"- **ğŸ“Œ æ¨æ–‡ID**: `{tweet.get('id', 'unknown')}`\n"
                f"{reference_section}"
                f"\n### ğŸ“ åŸæ–‡\n\n"
                f"{tweet.get('text', 'æ— å†…å®¹')}"
                f"{media_section}"
                f"{screenshot_section}"
            )
            
            # æ¨é€æ¶ˆæ¯
            success = self.push_queue.push(title, content)
            if success:
                logging.info(f"æˆåŠŸæ¨é€æ¨æ–‡: {tweet.get('id', 'unknown')}")
            else:
                logging.error(f"æ¨é€å¤±è´¥: {tweet.get('id', 'unknown')}")
                
            return success
            
        except Exception as e:
            logging.error(f"æ¨é€æ¨æ–‡æ—¶å‡ºé”™: {str(e)}")
            return False

    def parse_tweet_time(self, time_str: str) -> tuple:
        """è§£ææ¨æ–‡æ—¶é—´"""
        try:
            now = datetime.now(self.timezone)
            logging.debug(f"å¼€å§‹è§£ææ—¶é—´: {time_str}")
            
            # å¤„ç†ç›¸å¯¹æ—¶é—´æ ¼å¼ (ä¾‹å¦‚: "1h", "2h", "3m")
            if any(unit in time_str.lower() for unit in ['h', 'm', 's']):
                value = int(''.join(filter(str.isdigit, time_str)))
                unit = ''.join(filter(str.isalpha, time_str.lower()))
                logging.debug(f"æ£€æµ‹åˆ°ç›¸å¯¹æ—¶é—´æ ¼å¼: å€¼={value}, å•ä½={unit}")
                
                if unit == 'h':
                    delta = timedelta(hours=value)
                elif unit == 'm':
                    delta = timedelta(minutes=value)
                elif unit == 's':
                    delta = timedelta(seconds=value)
                else:
                    logging.warning(f"æœªçŸ¥çš„æ—¶é—´å•ä½: {unit} in {time_str}")
                    return now, "æœªçŸ¥æ—¶é—´"
                    
                parsed_time = now - delta
                logging.debug(f"ç›¸å¯¹æ—¶é—´è§£æç»“æœ: {parsed_time}")
                
            else:
                # å¤„ç†ç»å¯¹æ—¶é—´æ ¼å¼
                formats = [
                    '%d %b %Y',                    # 25 Dec 2024
                    '%d %b %Y Â· %H:%M',            # 25 Dec 2024 Â· 15:30
                    '%d %b %Y Â· %I:%M %p',         # 25 Dec 2024 Â· 3:30 PM
                    '%b %d, %Y Â· %I:%M %p %Z',     # Jan 23, 2024 Â· 10:30 AM UTC
                    '%b %d, %Y Â· %H:%M %Z',        # Jan 23, 2024 Â· 22:30 UTC
                    '%Y-%m-%d %H:%M:%S %Z',        # 2024-01-23 22:30:00 UTC
                    '%b %d, %Y',                   # Jan 23, 2024
                    '%b %d'                        # Jan 23
                ]
                
                logging.debug(f"å°è¯•è§£æç»å¯¹æ—¶é—´æ ¼å¼: {time_str}")
                parsed_time = None
                current_year = now.year
                
                for fmt in formats:
                    try:
                        if fmt == '%b %d':
                            # å¤„ç†åªæœ‰æœˆæ—¥çš„æƒ…å†µ
                            naive_time = datetime.strptime(f"{time_str}, {current_year}", '%b %d, %Y')
                            temp_time = self.timezone.localize(naive_time)
                            if temp_time > now:
                                naive_time = datetime.strptime(f"{time_str}, {current_year-1}", '%b %d, %Y')
                                temp_time = self.timezone.localize(naive_time)
                            parsed_time = temp_time
                            logging.debug(f"ä½¿ç”¨æ ¼å¼ {fmt} æˆåŠŸè§£ææ—¶é—´: {parsed_time}")
                            break
                        else:
                            naive_time = datetime.strptime(time_str, fmt)
                            parsed_time = self.timezone.localize(naive_time)
                            logging.debug(f"ä½¿ç”¨æ ¼å¼ {fmt} æˆåŠŸè§£ææ—¶é—´: {parsed_time}")
                            break
                    except ValueError:
                        logging.debug(f"æ ¼å¼ {fmt} è§£æå¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ ¼å¼")
                        continue
                
                if not parsed_time:
                    logging.warning(f"æ— æ³•è§£ææ—¶é—´æ ¼å¼: {time_str} (å°è¯•çš„æ ¼å¼: {formats})")
                    return now, "æœªçŸ¥æ—¶é—´"
            
            # æ ¼å¼åŒ–ä¸ºæ˜“è¯»çš„å­—ç¬¦ä¸²
            formatted_time = parsed_time.strftime('%Y-%m-%d %H:%M:%S')
            logging.info(f"æ—¶é—´è§£ææˆåŠŸ: {time_str} -> {formatted_time}")
            
            return parsed_time, formatted_time
            
        except Exception as e:
            logging.error(f"è§£ææ—¶é—´å‡ºé”™ ({time_str}): {str(e)}", exc_info=True)
            return now, "æœªçŸ¥æ—¶é—´"

    def is_duplicate_tweet(self, tweet: Dict, window_minutes: int = 30) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯é‡å¤æ¨æ–‡ï¼ˆçŸ­æ—¶é—´å†…ç›¸åŒå†…å®¹ï¼‰"""
        now = time.time()
        tweet_text = tweet.get('text', '')
        
        # è·å–æœ€è¿‘çš„æ¨æ–‡è®°å½•
        recent_tweets = self.archiver.get_recent_tweets(minutes=window_minutes)
        
        for old_tweet in recent_tweets:
            # è·³è¿‡è‡ªå·±
            if old_tweet['id'] == tweet['id']:
                continue
            
            # æ£€æŸ¥å†…å®¹ç›¸ä¼¼åº¦
            old_text = old_tweet.get('text', '')
            if self._calculate_similarity(tweet_text, old_text) > 0.85:  # 85%ç›¸ä¼¼åº¦
                logging.warning(
                    f"æ£€æµ‹åˆ°å¯èƒ½çš„é‡å¤æ¨æ–‡:\n"
                    f"æ–°æ¨æ–‡ ({tweet['id']}): {tweet_text[:100]}...\n"
                    f"æ—§æ¨æ–‡ ({old_tweet['id']}): {old_text[:100]}..."
                )
                return True
        
        return False

    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """è®¡ç®—ä¸¤æ®µæ–‡æœ¬çš„ç›¸ä¼¼åº¦ï¼ˆç®€å•å®ç°ï¼‰"""
        # è¿™é‡Œä½¿ç”¨ç®€å•çš„å­—ç¬¦åŒ¹é…ï¼Œå®é™…å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„ç®—æ³•
        s1 = set(text1.split())
        s2 = set(text2.split())
        
        if not s1 or not s2:
            return 0.0
        
        intersection = len(s1.intersection(s2))
        union = len(s1.union(s2))
        
        return intersection / union if union > 0 else 0.0

    def _process_user_updates(self, name: str, username: str) -> None:
        """å¤„ç†å•ä¸ªç”¨æˆ·çš„æ›´æ–°"""
        try:
            logging.info(f"æ­£åœ¨æ£€æŸ¥ {name} (@{username}) çš„æ›´æ–°...")
            tweets = self.get_tweets_with_retry(username)
            
            if not tweets:
                logging.warning(f"æœªè·å–åˆ° {name} çš„æ¨æ–‡")
                return
            
            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒºåˆ†ä¸åŒç±»å‹çš„æ¨æ–‡
            pinned_count = sum(1 for t in tweets if t.get('is_pinned', False))
            retweet_count = sum(1 for t in tweets if t.get('is_retweet', False))
            quote_count = sum(1 for t in tweets if t.get('is_quote', False))
            normal_count = len(tweets) - pinned_count - retweet_count - quote_count + (
                sum(1 for t in tweets if t.get('is_retweet', False) and t.get('is_quote', False))
                )  # ä¿®æ­£é‡å¤è®¡ç®—
            
            logging.info(
                f"è·å–åˆ° {len(tweets)} æ¡æ¨æ–‡ "
                f"(ç½®é¡¶: {pinned_count}, "
                f"è½¬å‘: {retweet_count}, "
                f"å¼•ç”¨: {quote_count}, "
                f"æ™®é€š: {normal_count})"
            )
            
            # ä¿®æ”¹æ—¶é—´æ£€æŸ¥é€»è¾‘
            now = datetime.now(self.timezone)
            three_days_ago = now - timedelta(days=3)
            valid_tweets = []
            old_tweets = []
            new_tweets = []
            exist_tweets = []
            
            logging.info(f"å¼€å§‹å¤„ç† {len(tweets)} æ¡æ¨æ–‡...")
            for tweet in tweets:
                can_send = True
                # æ£€æŸ¥æ¨æ–‡ID
                if not tweet.get('id'):
                    logging.error("æ¨æ–‡ç¼ºå°‘IDï¼Œè·³è¿‡å¤„ç†")
                    continue
                
                # è§£ææ¨æ–‡æ—¶é—´
                parsed_time, formatted_time = self.parse_tweet_time(tweet['time'])
                tweet['formatted_time'] = formatted_time
                
                # æ£€æŸ¥æ˜¯å¦å·²å‘é€è¿‡
                if self.archiver.is_sent(tweet['id']):
                    exist_tweets.append(tweet['id'])
                    logging.info(f"å·²å­˜åœ¨çš„æ¨æ–‡: {tweet['id']} ({formatted_time})")
                    can_send = False
                    
                
                # æ£€æŸ¥æ—¶é—´æ˜¯å¦åœ¨3å¤©å†…
                if parsed_time > three_days_ago:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯é‡å¤æ¨æ–‡
                    if self.is_duplicate_tweet(tweet):
                        logging.info(f"è·³è¿‡å¯èƒ½çš„é‡å¤æ¨æ–‡: {tweet['id']}")
                        can_send = False
                    new_tweets.append(tweet)
                    logging.debug(f"å‘ç°3å¤©å†…çš„æ¨æ–‡: {tweet['id']} ({formatted_time})")
                else:
                    old_tweets.append(tweet)
                    logging.debug(f"è¶…è¿‡3å¤©çš„æ¨æ–‡: {tweet['id']} ({formatted_time})")
                    can_send = False
                if can_send:
                    valid_tweets.append(tweet)
                    logging.debug(f"å‘ç°æ–°æ¨æ–‡: {tweet['id']} ({formatted_time})")
            
            logging.info(
                f"æ¨æ–‡ç»Ÿè®¡:\n"
                f"- æ€»æ•°: {len(tweets)} æ¡\n"
                f"- 3å¤©å†…: {len(new_tweets)} æ¡\n"
                f"- 3å¤©å¤–: {len(old_tweets)} æ¡\n"
                f"- æ–°æ¨æ–‡: {len(valid_tweets)} æ¡\n"
                f"- å·²å­˜åœ¨: {len(exist_tweets)} æ¡"
            )
            
            # å¤„ç†æ–°æ¨æ–‡
            for tweet in valid_tweets:
                try:
                    logging.info(
                    f"å¼€å§‹å¤„ç†æ–°æ¨æ–‡: {tweet['id']} "
                    f"{'[ç½®é¡¶]' if tweet.get('is_pinned') else ''}"
                    f"{'[è½¬å‘]' if tweet.get('is_retweet') else ''}"
                    f"{'[å¼•ç”¨]' if tweet.get('is_quote') else ''}"
                    f" ({tweet['formatted_time']})"
                    )

                    # æ„å»ºå®Œæ•´çš„æ¨æ–‡æ•°æ®
                    tweet_data = {
                        'id': tweet['id'],
                        'username': username,
                        'name': name,
                        'text': tweet['text'],
                        'time': tweet['time'],
                        'formatted_time': tweet['formatted_time'],
                        'url': tweet['url'],  # ä½¿ç”¨æ„å»ºçš„ URL
                        'is_pinned': tweet.get('is_pinned', False),
                        'is_retweet': tweet.get('is_retweet', False),
                        'is_quote': tweet.get('is_quote', False),
                        'retweet_author': tweet.get('retweet_author'),
                        'quote_text': tweet.get('quote_text'),
                        'quote_author': tweet.get('quote_author'),
                        'media': tweet.get('media', []),
                        'links': tweet.get('links', [])
                    }
                    
                    # å­˜æ¡£åŸå§‹æ¨æ–‡ï¼ˆä½†ä¸è®°å½•ä¸ºå·²å‘é€ï¼‰
                    self.archiver.archive_raw_tweet(tweet_data)
                    
                    # ç¿»è¯‘å’Œåˆ†æ
                    analysis = self.translator.analyze_tweet(tweet_data)
                    if not analysis:
                        # ç¿»è¯‘å¤±è´¥æˆ–æ— éœ€ç¿»è¯‘æ—¶çš„å¤„ç†
                        logging.warning(f"æ¨æ–‡æ— éœ€ç¿»è¯‘æˆ–ç¿»è¯‘å¤±è´¥: {tweet['id']}")
                        # ç¡®ä¿ tweet_id æ˜¯æ¸…ç†è¿‡çš„
                        tweet_id = tweet['id'].split('#')[0].split('?')[0]
                        image_url = f"{self.config.image_base_url}/images/{tweet_id}.png"
                        screenshot_section = (
                            f"\n### ğŸ“¸ æˆªå›¾\n\n"
                            f"![æ¨æ–‡æˆªå›¾]({image_url})\n"
                        )
                        # æ„å»ºåª’ä½“éƒ¨åˆ†
                        media_section = ""
                        if tweet_data.get('media'):
                            media_section = "\n### ğŸ“· åª’ä½“\n\n"
                            for media in tweet_data['media']:
                                media_type = media.get('type', 'unknown')
                                if media_type == 'image':
                                    media_section += f"![å›¾ç‰‡]({media.get('url')})\n"
                                elif media_type == 'video':
                                    media_section += f"ğŸ¬ [è§†é¢‘é“¾æ¥]({media.get('url')})\n"
                                elif media_type == 'gif':
                                    media_section += f"ğŸï¸ [GIF]({media.get('url')})\n"
                        
                        # æ„å»ºæ¨é€å†…å®¹
                        title = f"ã€{name}ã€‘{'[ä»…åª’ä½“]' if not tweet_data.get('text') else tweet_data['text'][:50]}"
                        content = (
                            "###  âš ï¸ ç¿»è¯‘å¤±è´¥\n\n"
                            "### â„¹ï¸ è¯¦ç»†ä¿¡æ¯\n\n"
                            f"- **ğŸ“… å‘å¸ƒæ—¶é—´**: {tweet_data.get('time','æœªçŸ¥')}\n"
                            f"- **ğŸ“… å‘å¸ƒæ—¥æœŸ**: {tweet_data.get('formatted_time','-')}\n"
                            f"- **ğŸ”— åŸæ–‡é“¾æ¥**: [ç‚¹å‡»æŸ¥çœ‹]({tweet_data.get('url', '#')})\n"
                            f"- **ğŸ“Œ æ¨æ–‡ID**: `{tweet_data.get('id', 'unknown')}`\n\n"
                            f"### ğŸ“ åŸæ–‡\n\n"
                            f"{tweet_data.get('text', 'æ— æ–‡å­—å†…å®¹')}"
                            f"{media_section}"
                            f"{screenshot_section}"
                        )
                        
                        # æ¨é€æ¶ˆæ¯å¹¶æ ‡è®°ä¸ºå·²å‘é€
                        if self.push_queue.push(title, content):
                            self.archiver.mark_as_sent(tweet_data['id'])
                            logging.info(f"æ— éœ€ç¿»è¯‘çš„æ¨æ–‡å¤„ç†å®Œæˆ: {tweet_data['id']}")
                        return
                    
                    # å­˜æ¡£ç¿»è¯‘ç»“æœ
                    self.archiver.archive_translation(tweet_data, analysis)
                    
                    # æ¨é€æ¶ˆæ¯å¹¶è®°å½•çŠ¶æ€
                    push_success = self.push_tweet(tweet_data, analysis)
                    # æ— è®ºæ¨é€æˆåŠŸä¸å¦ï¼Œéƒ½è®°å½•ä¸ºå·²å¤„ç†
                    self.archiver.mark_as_sent(tweet_data['id'])
                    
                    if push_success:
                        logging.info(f"æ¨æ–‡å¤„ç†å®Œæˆ: {tweet['id']}")
                    else:
                        logging.error(f"æ¨æ–‡æ¨é€å¤±è´¥: {tweet['id']}")
                    
                except requests.exceptions.RequestException as e:
                    logging.error(f"è¯·æ±‚ {name} çš„æ¨æ–‡æ—¶ç½‘ç»œé”™è¯¯: {str(e)}")
                    continue
                except ValueError as e:
                    logging.error(f"è§£æ {name} çš„æ¨æ–‡æ—¶å‡ºé”™: {str(e)}")
                    continue
                except Exception as e:
                    logging.error(f"å¤„ç† {name} çš„æ¨æ–‡æ—¶å‡ºç°æœªçŸ¥é”™è¯¯: {str(e)}", exc_info=True)
                    continue
                finally:
                    # æ— è®ºæ˜¯å¦æˆåŠŸï¼Œéƒ½ç­‰å¾…ä¸€æ®µéšæœºæ—¶é—´å†å¤„ç†ä¸‹ä¸€ä¸ªç”¨æˆ·
                    time.sleep(random.uniform(1, 3))
            
        except Exception as e:
            logging.error(f"å¤„ç† {name} çš„æ¨æ–‡æ—¶å‡ºç°é”™è¯¯: {str(e)}", exc_info=True)
        finally:
            time.sleep(random.uniform(1, 3)) 